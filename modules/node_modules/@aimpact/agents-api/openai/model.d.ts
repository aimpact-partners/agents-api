/************
Processor: ts
************/

import __beyond_dep_def_0 from 'openai';
// index.ts
declare namespace ns_0 {
  import OpenAI = __beyond_dep_def_0;
  interface ICompletionsParams {
    messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[];
    model?: string;
    temperature?: number;
  }
  export class OpenAIBackend {
    #private;
    completions({
      messages,
      model,
      temperature
    }: ICompletionsParams): Promise<{
      status: boolean;
      data: string;
      error?: undefined;
    } | {
      status: boolean;
      error: any;
      data?: undefined;
    }>;
  }
  export {};
}


// utils\models.ts
declare namespace ns_1 {
  export const models: Readonly<{
    GPT_4: "gpt-4";
    GPT_4_TURBO: "gpt-4-turbo";
    GPT_4O: "gpt-4o";
    GPT_4O_MINI: "gpt-4o-mini";
    GPT_3_5_TURBO: "gpt-3.5-turbo";
    GPT_3_5_TURBO_INSTRUCT: "gpt-3.5-turbo-instruct";
    GPT_3_5_TURBO_16K: "gpt-3.5-turbo-16k";
    DALL_E_2: "dall-e-2";
    DALL_E_3: "dall-e-3";
    WHISPER_1: "whisper-1";
    WHISPER_LARGE_V2: "whisper-large-v2";
    WHISPER_LARGE_V3: "whisper-large-v3";
  }>;
}


export import OpenAIBackend = ns_0.OpenAIBackend;
export import models = ns_1.models;

export declare const hmr: {on: (event: string, listener: any) => void, off: (event: string, listener: any) => void };